{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40ecf75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data...\n",
      "Performing clustering...\n",
      "Generating report...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chatu\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning:\n",
      "\n",
      "KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report generated successfully! Check 'comprehensive_clustering_report.pdf'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score, silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "def load_and_prepare_data():\n",
    "    # Load data\n",
    "    customers_df = pd.read_csv(\"C:\\\\Users\\\\chatu\\\\Downloads\\\\Customers.csv\")\n",
    "    transactions_df = pd.read_csv(\"C:\\\\Users\\\\chatu\\\\Downloads\\\\Transactions.csv\")\n",
    "    \n",
    "    # Convert dates\n",
    "    customers_df['SignupDate'] = pd.to_datetime(customers_df['SignupDate'])\n",
    "    transactions_df['TransactionDate'] = pd.to_datetime(transactions_df['TransactionDate'])\n",
    "    \n",
    "    # Calculate customer metrics\n",
    "    customer_metrics = transactions_df.groupby('CustomerID').agg({\n",
    "        'TransactionID': 'count',\n",
    "        'TotalValue': ['sum', 'mean'],\n",
    "        'Quantity': ['sum', 'mean']\n",
    "    }).reset_index()\n",
    "    \n",
    "    customer_metrics.columns = ['CustomerID', 'transaction_count', 'total_spend', \n",
    "                              'avg_transaction_value', 'total_quantity', 'avg_quantity']\n",
    "    \n",
    "    # Calculate days since signup\n",
    "    customers_df['days_since_signup'] = (datetime.now() - customers_df['SignupDate']).dt.days\n",
    "    \n",
    "    # Merge customer data\n",
    "    final_data = customers_df.merge(customer_metrics, on='CustomerID', how='left')\n",
    "    \n",
    "    # One-hot encode region\n",
    "    region_dummies = pd.get_dummies(final_data['Region'], prefix='region')\n",
    "    final_data = pd.concat([final_data, region_dummies], axis=1)\n",
    "    \n",
    "    return final_data\n",
    "\n",
    "def create_comprehensive_report(data, scaled_features, labels, db_score, silhouette_score):\n",
    "    # Create a large figure with subplots\n",
    "    plt.figure(figsize=(20, 25))\n",
    "    \n",
    "    # 1. Title and Metrics\n",
    "    plt.subplot(5, 1, 1)\n",
    "    plt.axis('off')\n",
    "    plt.text(0.5, 0.8, 'Customer Segmentation Analysis Report', \n",
    "            horizontalalignment='center', fontsize=20, fontweight='bold')\n",
    "    plt.text(0.5, 0.6, f'Number of Clusters: {len(np.unique(labels))}', \n",
    "            horizontalalignment='center', fontsize=12)\n",
    "    plt.text(0.5, 0.4, f'Davies-Bouldin Index: {db_score:.3f}', \n",
    "            horizontalalignment='center', fontsize=12)\n",
    "    plt.text(0.5, 0.2, f'Silhouette Score: {silhouette_score:.3f}', \n",
    "            horizontalalignment='center', fontsize=12)\n",
    "    \n",
    "    # 2. PCA Visualization\n",
    "    plt.subplot(5, 1, 2)\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_features = pca.fit_transform(scaled_features)\n",
    "    plt.scatter(pca_features[:, 0], pca_features[:, 1], c=labels, cmap='viridis')\n",
    "    plt.title('Customer Segments - PCA Visualization')\n",
    "    plt.xlabel('First Principal Component')\n",
    "    plt.ylabel('Second Principal Component')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    # 3. Cluster Profiles\n",
    "    plt.subplot(5, 1, 3)\n",
    "    cluster_profiles = data.groupby('Cluster').agg({\n",
    "        'total_spend': 'mean',\n",
    "        'transaction_count': 'mean',\n",
    "        'avg_transaction_value': 'mean'\n",
    "    }).round(2)\n",
    "    \n",
    "    cluster_profiles.plot(kind='bar', ax=plt.gca())\n",
    "    plt.title('Cluster Profiles - Key Metrics')\n",
    "    plt.xlabel('Cluster')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 4. Region Distribution\n",
    "    plt.subplot(5, 1, 4)\n",
    "    region_cols = [col for col in data.columns if col.startswith('region_')]\n",
    "    region_dist = data.groupby('Cluster')[region_cols].mean()\n",
    "    region_dist.plot(kind='bar', stacked=True, ax=plt.gca())\n",
    "    plt.title('Region Distribution by Cluster')\n",
    "    plt.xlabel('Cluster')\n",
    "    plt.ylabel('Proportion')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 5. Key Statistics Table\n",
    "    plt.subplot(5, 1, 5)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    stats_text = \"\"\"\n",
    "    Key Insights:\n",
    "    \n",
    "    1. Cluster Sizes:\n",
    "    {}\n",
    "    \n",
    "    2. Average Spend per Cluster:\n",
    "    {}\n",
    "    \n",
    "    3. Transaction Frequency:\n",
    "    {}\n",
    "    \n",
    "    4. Regional Distribution:\n",
    "    {}\n",
    "    \"\"\".format(\n",
    "        data.groupby('Cluster').size().to_string(),\n",
    "        data.groupby('Cluster')['total_spend'].mean().round(2).to_string(),\n",
    "        data.groupby('Cluster')['transaction_count'].mean().round(2).to_string(),\n",
    "        region_dist.mean().round(2).to_string()\n",
    "    )\n",
    "    \n",
    "    plt.text(0, 1, stats_text, fontsize=10, va='top', family='monospace')\n",
    "    \n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('comprehensive_clustering_report.pdf', bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        print(\"Loading and preparing data...\")\n",
    "        data = load_and_prepare_data()\n",
    "        \n",
    "        # Prepare features for clustering\n",
    "        feature_columns = ['days_since_signup', 'transaction_count', 'total_spend', \n",
    "                         'avg_transaction_value', 'total_quantity', 'avg_quantity']\n",
    "        region_columns = [col for col in data.columns if col.startswith('region_')]\n",
    "        feature_columns.extend(region_columns)\n",
    "        \n",
    "        features = data[feature_columns].fillna(0)\n",
    "        scaler = StandardScaler()\n",
    "        scaled_features = scaler.fit_transform(features)\n",
    "        \n",
    "        # Perform clustering\n",
    "        print(\"Performing clustering...\")\n",
    "        n_clusters = 4  # You can adjust this number\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        labels = kmeans.fit_predict(scaled_features)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        db_score = davies_bouldin_score(scaled_features, labels)\n",
    "        silhouette = silhouette_score(scaled_features, labels)\n",
    "        \n",
    "        # Add cluster labels to data\n",
    "        data['Cluster'] = labels\n",
    "        \n",
    "        # Create report\n",
    "        print(\"Generating report...\")\n",
    "        create_comprehensive_report(data, scaled_features, labels, db_score, silhouette)\n",
    "        \n",
    "        print(\"Report generated successfully! Check 'comprehensive_clustering_report.pdf'\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6902a4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
